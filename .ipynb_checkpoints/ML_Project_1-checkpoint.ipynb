{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf5f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import helpers as helpers\n",
    "import implementations as impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0118fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, train_labels, ids = helpers.load_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e5e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize data\n",
    "new_data = helpers.standardize(helpers.clean_data(train_data))\n",
    "train_labels[train_labels==-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec94e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "train_labels, new_data = helpers.shuffle_data(train_labels, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412a18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice into training and validation sets\n",
    "y_validation, y_train, tx_validation, tx_train = helpers.slice_data(train_labels, new_data, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d7fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias to data\n",
    "tx_train = np.c_[np.ones((y_train.shape[0], 1)), tx_train]\n",
    "tx_validation = np.c_[np.ones((y_validation.shape[0], 1)), tx_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30513e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.7163567950814637\n",
      "Current iteration=100, loss=0.6227581517924388\n",
      "Current iteration=200, loss=0.584904560206431\n",
      "Current iteration=300, loss=0.5641307100362333\n",
      "Current iteration=400, loss=0.5512503018068267\n",
      "Current iteration=500, loss=0.5426562963788715\n",
      "Current iteration=600, loss=0.5366105979203447\n",
      "Current iteration=700, loss=0.5321775687371848\n",
      "Current iteration=800, loss=0.5288137652729488\n",
      "Current iteration=900, loss=0.526185117200647\n"
     ]
    }
   ],
   "source": [
    "# Initialize the weights randomly according to a Gaussian distribution\n",
    "initial_w = np.random.normal(0., 0.1, [tx_train.shape[1],])\n",
    "\n",
    "# Train model\n",
    "trained_weights, train_loss = impl.logistic_regression(y_train, tx_train, initial_w, max_iters=1000, gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9288e049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63052585 -0.04999879 -0.5173932  -0.08092778  0.00691948  0.09996688\n",
      "  0.14235612 -0.07642688  0.26022932 -0.12728135  0.23888175 -0.23496718\n",
      "  0.31161957  0.15073612  0.29079516  0.01716182 -0.00413932  0.10489579\n",
      " -0.02860195  0.01493111  0.05025261 -0.01344014 -0.03807062 -0.09740716\n",
      " -0.05989901  0.015122   -0.00314341 -0.15312257 -0.00116578 -0.00306518\n",
      "  0.09697944]\n"
     ]
    }
   ],
   "source": [
    "print(trained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf50be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy = 0.7350986666666667\n",
      "validation_accuracy = 0.735232\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "predict_validation = helpers.predict_logistic(tx_validation, trained_weights)\n",
    "predict_train = helpers.predict_logistic(tx_train, trained_weights)\n",
    "\n",
    "predict_validation[predict_validation == -1] = 0\n",
    "predict_train[predict_train == -1] = 0\n",
    "\n",
    "train_accuracy = helpers.accuracy(predict_train, y_train)\n",
    "validation_accuracy = helpers.accuracy(predict_validation, y_validation)\n",
    "\n",
    "print(f\"train_accuracy = {train_accuracy}\")\n",
    "print(f\"validation_accuracy = {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951c19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[1. 0. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(predict_validation)\n",
    "print(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5193e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tx_test, y_test, ids_test \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tx_test \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mstandardize(helpers\u001b[38;5;241m.\u001b[39mclean_data(tx_test))\n",
      "File \u001b[0;32m~/Documents/MA1/ml-project-1-md_am_af-project1/helpers.py:14\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(path_dataset, sub_sample, add_outlier, train)\u001b[0m\n\u001b[1;32m     12\u001b[0m     labels[labels\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(labels, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, ids\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/numpy/lib/function_base.py:5183\u001b[0m, in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   5180\u001b[0m         keep[obj,] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   5182\u001b[0m     slobj[axis] \u001b[38;5;241m=\u001b[39m keep\n\u001b[0;32m-> 5183\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mslobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   5185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m   5186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(new)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tx_test, y_test, ids_test = helpers.load_data('test.csv', train=False)\n",
    "tx_test = helpers.standardize(helpers.clean_data(tx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6922cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test = np.c_[np.ones((y_test.shape[0], 1)), tx_test]\n",
    "predict_test = helpers.predict_logistic(tx_test, trained_weights)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.create_csv_submission(ids_test, predict_test, 'Predictions_Logistics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
